{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the necessery libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ivanyanakiev1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from inverted_index import InvertedIndex\n",
    "import nltk\n",
    "from utils import read_data\n",
    "nltk.download('stopwords')\n",
    "inv_ind = InvertedIndex()\n",
    "\n",
    "# Initialization done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will now proceed to read the documents from the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = read_data(\"./shakespeare\")\n",
    "# Print the first 1 documents\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the number of the documents as well as their document title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(documents))\n",
    "for i in documents:\n",
    "    # Print document title\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add documents to the inverted matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in documents:\n",
    "    # Add document to inverted index\n",
    "    inv_ind.add_document(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print come descriptives so that we can verify everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19202\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(inv_ind.get_total_terms())\n",
    "print(inv_ind.get_total_docs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a term by document matrix using log entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Log-Entropy and the 2 components of it\n",
    "Log-Entropy is a statistical analysis of probabilities and calculation of a surprise \"index\" when certain event occurs. For example \n",
    "if a certain event has 90% chance to occur then the Log-Entropy of that event will be low since the surprise factor will be low.\n",
    "\n",
    "### Component 1\n",
    "1. This is the logarithm of the term frequency of i in document j. The term frequency can be better described as the probability of term i to occur in document j.\n",
    "Since this term occurs multiple times throughout one document (potentially or 0) we will need to multiply the natural log of it to the next component.\n",
    "\n",
    "### Component 2\n",
    "2. The second term can be interpreted as the actual amount of surprise given a discrete variable X and it's probability P(X). In order to compute the surprise\n",
    "we need the frequency of the term in the current document in regards to the total fequency.This number will of course be less than 1 and can be interpreted as yet another probability of occurance of the discrete variable X or in our case the term. We then divide by the log of the total number of documents and this final value tha we would have would represent the surprise of occurance of term i. If surprise is low then probability was high, if surprise is high then probability was low.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix(log_entropy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a search query: \"scotland kings and thanes\" using the Log-Entropy weighting scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.07769052662351016)\n",
      "('King Henry VI', 0.031869310554797074)\n",
      "('King Henry IV', 0.030208435869742898)\n",
      "('King Henry IV, II', 0.028145973814360462)\n",
      "('King John', 0.027447611557131362)\n",
      "('King Henry V', 0.027437757231046665)\n",
      "('King Richard III', 0.026833074525408347)\n",
      "('King Richard II', 0.02678812593487038)\n",
      "('King Henry VIII', 0.02590799663639283)\n",
      "(\"All's Well that Ends Well\", 0.025433109729848902)\n"
     ]
    }
   ],
   "source": [
    "result = inv_ind.search(\"scotland kings and thanes\",log_entropy=True,cos_com = True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate term by document matrix without using TF model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.generate_term_by_doc_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on the same data set with the same query and print top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('King Henry V', 0.2659215354074205)\n",
      "('King Henry VI', 0.2617837075388672)\n",
      "('King John', 0.2472493685181954)\n",
      "('King Richard II', 0.2253953514359277)\n",
      "('King Lear', 0.20415867029886436)\n",
      "('King Henry VIII', 0.1998881836179047)\n",
      "('King Richard III', 0.18418950223762484)\n",
      "('Hamlet', 0.1241932011402115)\n",
      "(\"All's Well that Ends Well\", 0.11190811971898096)\n",
      "('King Henry IV', 0.10791586179996365)\n"
     ]
    }
   ],
   "source": [
    "result = inv_ind.search(\"scotland kings and thanes\",cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate term by doc matrix using the TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix(tfidf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test again on the same query and print the top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.08559316237351267)\n",
      "('King Henry IV', 0.005789261723483593)\n",
      "('King Henry VI', 0.003660436049077642)\n",
      "('King Henry IV, II', 0.003121709934588564)\n",
      "('King Henry V', 0.0019193400093131976)\n",
      "('King Richard III', 0.0013431147327243318)\n",
      "('King John', 0.0007488196759316429)\n",
      "('King Richard II', 0.0006742482860831404)\n",
      "('King Henry VIII', 0.0005161221482695165)\n",
      "('The Comedy of Errors', 0.00046244490997942336)\n"
     ]
    }
   ],
   "source": [
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf= True,cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Log-Entropy work better than or worse than TF and TF-IDf\n",
    "1. It performs better than TF since TF tends to favor longer documents since it looks at only the term frequency, thus relative global frequencies are ignored\n",
    "2. Log-Entropy is calculated based on probabilities and tries to determine the surprise of seeing a term, in its calculation more factors are accounted for\n",
    "such as frequency in current doc vs total frequency\n",
    "3. Looking at the test data from the example showed in class we can determine that TF-IDF could be stated that is comparable to Log-Entropy if we look at the results.\n",
    "They are very similar in nature and the rankings are also nearly the same only with few rotations here and there.\n",
    "\n",
    "### Conclusion\n",
    "From the results we can conclude that the Log-Entropy model represents definitely more accurate solutions than the TF model only and data would suggest slight improvement over the TF-IDF model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of part B Comparision Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the \"scotland kings and thanes\" but using TF method with Euclidian Distance as comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('King Henry V', 0.2659215354074205)\n",
      "('King Henry VI', 0.2617837075388672)\n",
      "('King John', 0.2472493685181954)\n",
      "('King Richard II', 0.2253953514359277)\n",
      "('King Lear', 0.20415867029886436)\n",
      "('King Henry VIII', 0.1998881836179047)\n",
      "('King Richard III', 0.18418950223762484)\n",
      "('Hamlet', 0.1241932011402115)\n",
      "(\"All's Well that Ends Well\", 0.11190811971898096)\n",
      "('King Henry IV', 0.10791586179996365)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for \"scotland kings and thanes\" using TF method with Pearson Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('King Henry V', 0.2659215354074205)\n",
      "('King Henry VI', 0.2617837075388672)\n",
      "('King John', 0.2472493685181954)\n",
      "('King Richard II', 0.2253953514359277)\n",
      "('King Lear', 0.20415867029886436)\n",
      "('King Henry VIII', 0.1998881836179047)\n",
      "('King Richard III', 0.18418950223762484)\n",
      "('Hamlet', 0.1241932011402115)\n",
      "(\"All's Well that Ends Well\", 0.11190811971898096)\n",
      "('King Henry IV', 0.10791586179996365)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",pear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF method with Spearman Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('King Henry V', 0.2659215354074205)\n",
      "('King Henry VI', 0.2617837075388672)\n",
      "('King John', 0.2472493685181954)\n",
      "('King Richard II', 0.2253953514359277)\n",
      "('King Lear', 0.20415867029886436)\n",
      "('King Henry VIII', 0.1998881836179047)\n",
      "('King Richard III', 0.18418950223762484)\n",
      "('Hamlet', 0.1241932011402115)\n",
      "(\"All's Well that Ends Well\", 0.11190811971898096)\n",
      "('King Henry IV', 0.10791586179996365)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",spear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF method with Kendalltau Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('King Henry V', 0.2659215354074205)\n",
      "('King Henry VI', 0.2617837075388672)\n",
      "('King John', 0.2472493685181954)\n",
      "('King Richard II', 0.2253953514359277)\n",
      "('King Lear', 0.20415867029886436)\n",
      "('King Henry VIII', 0.1998881836179047)\n",
      "('King Richard III', 0.18418950223762484)\n",
      "('Hamlet', 0.1241932011402115)\n",
      "(\"All's Well that Ends Well\", 0.11190811971898096)\n",
      "('King Henry IV', 0.10791586179996365)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",kend_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF-IDF method with Cosine comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.08559316237351267)\n",
      "('King Henry IV', 0.005789261723483593)\n",
      "('King Henry VI', 0.003660436049077642)\n",
      "('King Henry IV, II', 0.003121709934588564)\n",
      "('King Henry V', 0.0019193400093131976)\n",
      "('King Richard III', 0.0013431147327243318)\n",
      "('King John', 0.0007488196759316429)\n",
      "('King Richard II', 0.0006742482860831404)\n",
      "('King Henry VIII', 0.0005161221482695165)\n",
      "('The Comedy of Errors', 0.00046244490997942336)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix(tfidf=True)\n",
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf=True,cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF-IDF method with Euclidian Distance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.08559316237351267)\n",
      "('King Henry IV', 0.005789261723483593)\n",
      "('King Henry VI', 0.003660436049077642)\n",
      "('King Henry IV, II', 0.003121709934588564)\n",
      "('King Henry V', 0.0019193400093131976)\n",
      "('King Richard III', 0.0013431147327243318)\n",
      "('King John', 0.0007488196759316429)\n",
      "('King Richard II', 0.0006742482860831404)\n",
      "('King Henry VIII', 0.0005161221482695165)\n",
      "('The Comedy of Errors', 0.00046244490997942336)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix(tfidf=True)\n",
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf=True,euc_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for  \"scotland kings and thanes \" using TF-IDF method with Pearson Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.08559316237351267)\n",
      "('King Henry IV', 0.005789261723483593)\n",
      "('King Henry VI', 0.003660436049077642)\n",
      "('King Henry IV, II', 0.003121709934588564)\n",
      "('King Henry V', 0.0019193400093131976)\n",
      "('King Richard III', 0.0013431147327243318)\n",
      "('King John', 0.0007488196759316429)\n",
      "('King Richard II', 0.0006742482860831404)\n",
      "('King Henry VIII', 0.0005161221482695165)\n",
      "('The Comedy of Errors', 0.00046244490997942336)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix(tfidf=True)\n",
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf=True,pear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF-IDF method with Spearman Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.08559316237351267)\n",
      "('King Henry IV', 0.005789261723483593)\n",
      "('King Henry VI', 0.003660436049077642)\n",
      "('King Henry IV, II', 0.003121709934588564)\n",
      "('King Henry V', 0.0019193400093131976)\n",
      "('King Richard III', 0.0013431147327243318)\n",
      "('King John', 0.0007488196759316429)\n",
      "('King Richard II', 0.0006742482860831404)\n",
      "('King Henry VIII', 0.0005161221482695165)\n",
      "('The Comedy of Errors', 0.00046244490997942336)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix(tfidf=True)\n",
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf=True,spear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF-IDF method with Kendalltau Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.08559316237351267)\n",
      "('King Henry IV', 0.005789261723483593)\n",
      "('King Henry VI', 0.003660436049077642)\n",
      "('King Henry IV, II', 0.003121709934588564)\n",
      "('King Henry V', 0.0019193400093131976)\n",
      "('King Richard III', 0.0013431147327243318)\n",
      "('King John', 0.0007488196759316429)\n",
      "('King Richard II', 0.0006742482860831404)\n",
      "('King Henry VIII', 0.0005161221482695165)\n",
      "('The Comedy of Errors', 0.00046244490997942336)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix(tfidf=True)\n",
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf=True,kend_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using Log-Entropy with Cosine comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.07769052662351016)\n",
      "('King Henry VI', 0.031869310554797074)\n",
      "('King Henry IV', 0.030208435869742898)\n",
      "('King Henry IV, II', 0.028145973814360462)\n",
      "('King John', 0.027447611557131362)\n",
      "('King Henry V', 0.027437757231046665)\n",
      "('King Richard III', 0.026833074525408347)\n",
      "('King Richard II', 0.02678812593487038)\n",
      "('King Henry VIII', 0.02590799663639283)\n",
      "(\"All's Well that Ends Well\", 0.025433109729848902)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix(log_entropy=True)\n",
    "result = inv_ind.search(\"scotland kings and thanes\",log_entropy=True,cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using Log-Entropy with Pearson Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.07769052662351016)\n",
      "('King Henry VI', 0.031869310554797074)\n",
      "('King Henry IV', 0.030208435869742898)\n",
      "('King Henry IV, II', 0.028145973814360462)\n",
      "('King John', 0.027447611557131362)\n",
      "('King Henry V', 0.027437757231046665)\n",
      "('King Richard III', 0.026833074525408347)\n",
      "('King Richard II', 0.02678812593487038)\n",
      "('King Henry VIII', 0.02590799663639283)\n",
      "(\"All's Well that Ends Well\", 0.025433109729848902)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix(log_entropy=True)\n",
    "result = inv_ind.search(\"scotland kings and thanes\",log_entropy=True,pear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using Log-Entropy with Spearman Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.07769052662351016)\n",
      "('King Henry VI', 0.031869310554797074)\n",
      "('King Henry IV', 0.030208435869742898)\n",
      "('King Henry IV, II', 0.028145973814360462)\n",
      "('King John', 0.027447611557131362)\n",
      "('King Henry V', 0.027437757231046665)\n",
      "('King Richard III', 0.026833074525408347)\n",
      "('King Richard II', 0.02678812593487038)\n",
      "('King Henry VIII', 0.02590799663639283)\n",
      "(\"All's Well that Ends Well\", 0.025433109729848902)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix(log_entropy=True)\n",
    "result = inv_ind.search(\"scotland kings and thanes\",log_entropy=True,spear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using Log-Entropy with Kendalltau Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.07769052662351016)\n",
      "('King Henry VI', 0.031869310554797074)\n",
      "('King Henry IV', 0.030208435869742898)\n",
      "('King Henry IV, II', 0.028145973814360462)\n",
      "('King John', 0.027447611557131362)\n",
      "('King Henry V', 0.027437757231046665)\n",
      "('King Richard III', 0.026833074525408347)\n",
      "('King Richard II', 0.02678812593487038)\n",
      "('King Henry VIII', 0.02590799663639283)\n",
      "(\"All's Well that Ends Well\", 0.025433109729848902)\n"
     ]
    }
   ],
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix(log_entropy=True)\n",
    "result = inv_ind.search(\"scotland kings and thanes\",log_entropy=True,kend_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from the overall experiment\n",
    "1. Euclidian distance if most prone to produce out-lier results\n",
    "2. All of the other methods: Spearman,Pearson,Kendall Tau produce nearly the same results as cosine comparison thus can conclude that\n",
    "generally the difference should not be big between using one or the other.We can give this extreme similarity between the methods to the length of the vectors\n",
    "since below we can see that on smaller vectorswe can see the difference even if it is very small. However, using such small values since our range is probably between\n",
    "0 and 3, and we have lengthy vectors the difference becomes much much lower essentially no difference between the methods. \n",
    "### NOTE idk if exactly true cuz jypiter notebook bad at restarts\n",
    "Euclidean seems to have outliers but maybe due to consistent offsets and long vectors then null out in the end and have the same output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different methods on a 2 vectors\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "print(inv_ind.cosine_comparison(a,b))\n",
    "print(inv_ind.pearson_comparison(a,b))\n",
    "print(inv_ind.spearman_comparison(a,b))\n",
    "print(inv_ind.euclidian_comparison(a,b))\n",
    "print(inv_ind.kendalltau_comparison(a,b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
