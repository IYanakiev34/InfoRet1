{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the necessery libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverted_index import InvertedIndex\n",
    "import nltk\n",
    "from utils import read_data\n",
    "nltk.download('stopwords')\n",
    "inv_ind = InvertedIndex()\n",
    "\n",
    "# Initialization done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will now proceed to read the documents from the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = read_data(\"./shakespeare\")\n",
    "# Print the first 1 documents\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the number of the documents as well as their document title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(documents))\n",
    "for i in documents:\n",
    "    # Print document title\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add documents to the inverted matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in documents:\n",
    "    # Add document to inverted index\n",
    "    inv_ind.add_document(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print come descriptives so that we can verify everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inv_ind.get_total_terms())\n",
    "print(inv_ind.get_total_docs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a term by document matrix using log entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Log-Entropy and the 2 components of it\n",
    "Log-Entropy is a statistical analysis of probabilities and calculation of a surprise \"index\" when certain event occurs. For example \n",
    "if a certain event has 90% chance to occur then the Log-Entropy of that event will be low since the surprise factor will be low.\n",
    "\n",
    "### Component 1\n",
    "1. This is the logarithm of the term frequency of i in document j. The term frequency can be better described as the probability of term i to occur in document j.\n",
    "Since this term occurs multiple times throughout one document (potentially or 0) we will need to multiply the natural log of it to the next component.\n",
    "\n",
    "### Component 2\n",
    "2. The second term can be interpreted as the actual amount of surprise given a discrete variable X and it's probability P(X). In order to compute the surprise\n",
    "we need the frequency of the term in the current document in regards to the total fequency.This number will of course be less than 1 and can be interpreted as yet another probability of occurance of the discrete variable X or in our case the term. We then divide by the log of the total number of documents and this final value tha we would have would represent the surprise of occurance of term i. If surprise is low then probability was high, if surprise is high then probability was low.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix(log_entropy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a search query: \"scotland kings and thanes\" using the Log-Entropy weighting scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inv_ind.search(\"scotland kings and thanes\",log_entropy=True,cos_com = True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate term by document matrix without using TF model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.generate_term_by_doc_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on the same data set with the same query and print top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inv_ind.search(\"scotland kings and thanes\",cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate term by doc matrix using the TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test again on the same query and print the top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf= True,cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Log-Entropy work better than or worse than TF and TF-IDf\n",
    "1. It performs better than TF since TF tends to favor longer documents since it looks at only the term frequency, thus relative global frequencies are ignored\n",
    "2. Log-Entropy is calculated based on probabilities and tries to determine the surprise of seeing a term, in its calculation more factors are accounted for\n",
    "such as frequency in current doc vs total frequency\n",
    "3. Looking at the test data from the example showed in class we can determine that TF-IDF could be stated that is comparable to Log-Entropy if we look at the results.\n",
    "They are very similar in nature and the rankings are also nearly the same only with few rotations here and there.\n",
    "\n",
    "### Conclusion\n",
    "From the results we can conclude that the Log-Entropy model represents definitely more accurate solutions than the TF model only and data would suggest slight improvement over the TF-IDF model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of part B Comparision Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the \"scotland kings and thanes\" but using TF method with Euclidian Distance as comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for \"scotland kings and thanes\" using TF method with Pearson Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",pear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF method with Spearman Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",spear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF method with Kendalltau Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",kend_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF-IDF method with Cosine comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf=True,cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF-IDF method with Euclidian Distance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf=True,cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for  \"scotland kings and thanes \" using TF-IDF method with Pearson Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf=True,pear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF-IDF method with Spearman Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf=True,spear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using TF-IDF method with Kendalltau Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",tfidf=True,kend_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using Log-Entropy with Cosine comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",log_entropy=True,cos_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using Log-Entropy with Pearson Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",log_entropy=True,pear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using Log-Entropy with Spearman Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",log_entropy=True,spear_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"scotland kings and thanes\" using Log-Entropy with Spearman Correlation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix()\n",
    "result = inv_ind.search(\"scotland kings and thanes\",log_entropy=True,kend_com=True)\n",
    "for i in range(0,10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from the overall experiment\n",
    "1. Euclidian distance if most prone to produce out-lier results\n",
    "2. All of the other methods: Spearman,Pearson,Kendall Tau produce nearly the same results as cosine comparison thus can conclude that\n",
    "generally the difference should not be big between using one or the other. \n",
    "### NOTE idk if exactly true cuz jypiter notebook bad at restarts\n",
    "Euclidean seems to have outliers but maybe due to consistent offsets and long vectors then null out in the end and have the same output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different methods on a 2 vectors\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "print(inv_ind.cosine_comparison(a,b))\n",
    "print(inv_ind.pearson_comparison(a,b))\n",
    "print(inv_ind.spearman_comparison(a,b))\n",
    "print(inv_ind.euclidian_comparison(a,b))\n",
    "print(inv_ind.kendalltau_comparison(a,b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
